{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total poms: ', 1468384)\n",
      "root\n",
      " |-- age_rating: string (nullable = true)\n",
      " |-- av_type: string (nullable = true)\n",
      " |-- available_subtitles: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- language: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- broadcasters: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- countries: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- creation_date: string (nullable = true)\n",
      " |-- credits: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- family_name: string (nullable = true)\n",
      " |    |    |-- given_name: string (nullable = true)\n",
      " |    |    |-- role: string (nullable = true)\n",
      " |-- descendant_of: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- mid_ref: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- descriptions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- embeddable: boolean (nullable = true)\n",
      " |-- episodeOf: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- date_added: string (nullable = true)\n",
      " |    |    |-- highlighted: boolean (nullable = true)\n",
      " |    |    |-- index: string (nullable = true)\n",
      " |    |    |-- mid_ref: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- terms: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- has_subtitles: boolean (nullable = true)\n",
      " |-- mid: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- creation_date: string (nullable = true)\n",
      " |    |    |-- credits: string (nullable = true)\n",
      " |    |    |-- date: string (nullable = true)\n",
      " |    |    |-- desription: string (nullable = true)\n",
      " |    |    |-- height: string (nullable = true)\n",
      " |    |    |-- highlighted: boolean (nullable = true)\n",
      " |    |    |-- image_uri: string (nullable = true)\n",
      " |    |    |-- last_modified_date: string (nullable = true)\n",
      " |    |    |-- license: string (nullable = true)\n",
      " |    |    |-- offset: string (nullable = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- source_name: string (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- width: string (nullable = true)\n",
      " |    |    |-- workflow: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- last_modified_date: string (nullable = true)\n",
      " |-- locations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- av_file_format: string (nullable = true)\n",
      " |    |    |-- creation_date: string (nullable = true)\n",
      " |    |    |-- last_modified_date: string (nullable = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- platform: string (nullable = true)\n",
      " |    |    |-- program_url: string (nullable = true)\n",
      " |    |    |-- publish_start: string (nullable = true)\n",
      " |    |    |-- publish_stop: string (nullable = true)\n",
      " |    |    |-- workflow: string (nullable = true)\n",
      " |-- memberOf: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- date_added: string (nullable = true)\n",
      " |    |    |-- highlighted: boolean (nullable = true)\n",
      " |    |    |-- index: string (nullable = true)\n",
      " |    |    |-- mid_ref: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- predictions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- platform: string (nullable = true)\n",
      " |    |    |-- publish_start: string (nullable = true)\n",
      " |    |    |-- publish_stop: string (nullable = true)\n",
      " |    |    |-- state: string (nullable = true)\n",
      " |-- publish_date: string (nullable = true)\n",
      " |-- regions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- revision: string (nullable = true)\n",
      " |-- schedule_events: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- channel: string (nullable = true)\n",
      " |    |    |-- duration: string (nullable = true)\n",
      " |    |    |-- guide_day: string (nullable = true)\n",
      " |    |    |-- is_rerun: boolean (nullable = true)\n",
      " |    |    |-- mid_ref: string (nullable = true)\n",
      " |    |    |-- net: string (nullable = true)\n",
      " |    |    |-- start: string (nullable = true)\n",
      " |    |    |-- text_subtitles: string (nullable = true)\n",
      " |-- sequence: string (nullable = true)\n",
      " |-- sortDate: string (nullable = true)\n",
      " |-- titles: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- workflow: string (nullable = true)\n",
      " |-- isYouth: boolean (nullable = true)\n",
      " |-- isPlayable: boolean (nullable = true)\n",
      " |-- seriesRef: string (nullable = true)\n",
      " |-- seasonRef: string (nullable = true)\n",
      " |-- broadcaster: string (nullable = true)\n",
      " |-- scheduleEventStart: string (nullable = true)\n",
      " |-- part_of_collection: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poms = spark.read.parquet(\"gs://mit-processed-events-prod.npo-data.nl/poms-enriched/\")\n",
    "print(\"Total poms: \", poms.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Filtered poms: ', 105105)\n",
      "root\n",
      " |-- broadcaster: string (nullable = true)\n",
      " |-- credits: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- family_name: string (nullable = true)\n",
      " |    |    |-- given_name: string (nullable = true)\n",
      " |    |    |-- role: string (nullable = true)\n",
      " |-- descriptions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- terms: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- mid: string (nullable = true)\n",
      " |-- locations: struct (nullable = true)\n",
      " |    |-- av_file_format: string (nullable = true)\n",
      " |    |-- creation_date: string (nullable = true)\n",
      " |    |-- last_modified_date: string (nullable = true)\n",
      " |    |-- owner: string (nullable = true)\n",
      " |    |-- platform: string (nullable = true)\n",
      " |    |-- program_url: string (nullable = true)\n",
      " |    |-- publish_start: string (nullable = true)\n",
      " |    |-- publish_stop: string (nullable = true)\n",
      " |    |-- workflow: string (nullable = true)\n",
      " |-- seriesRef: string (nullable = true)\n",
      " |-- titles: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- owner: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- program_url: string (nullable = true)\n",
      " |-- platform: string (nullable = true)\n",
      " |-- publish_start: string (nullable = true)\n",
      " |-- publish_stop: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gain broadcasts that are able to be streamed on NPO Start\n",
    "poms = (\n",
    "    poms\n",
    "    .filter(sf.col(\"type\")==\"BROADCAST\")\n",
    "    .filter(sf.size(\"locations\") > 0)\n",
    "    .select('broadcaster', 'credits', 'descriptions', 'genres', 'mid', 'locations', 'seriesRef', 'titles')\n",
    "    .withColumn('locations', sf.explode('locations'))\n",
    "    .withColumn('program_url', sf.col('locations.program_url'))\n",
    "    .withColumn('platform', sf.col('locations.platform'))\n",
    "    .withColumn('publish_start', sf.col('locations.publish_start'))\n",
    "    .withColumn('publish_stop', sf.col('locations.publish_stop'))\n",
    "    .filter(sf.col('program_url').startswith('npo+drm://') | sf.col('program_url').startswith('npo://'))\n",
    "    .filter((sf.col('platform') == 'INTERNETVOD') | (sf.col('platform') == 'PLUSVOD'))\n",
    "    .filter((sf.col('publish_start') != '0') | (sf.col('publish_stop') != '0'))\n",
    "    .filter(~sf.col('seriesRef').isNull())\n",
    ")\n",
    "print(\"Filtered poms: \", poms.count())\n",
    "poms.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+-----------+------------------+--------------------+\n",
      "|broadcaster|             credits|        descriptions|              genres|        mid|         seriesRef|              titles|\n",
      "+-----------+--------------------+--------------------+--------------------+-----------+------------------+--------------------+\n",
      "|        NOS|[[Meulens, Milous...|[[NEBO, MAIN, De ...|[[3.0.1.1, [Jeugd...| 9Jeugd1230| POMS_S_NOS_105306|[[NEBO, MAIN, NOS...|\n",
      "|        RVU|                  []|[[NEBO, MAIN, Sim...|[[3.0.1.7, [Infor...| RVU_102368|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[BROADCASTER, SH...|                  []| RVU_102939|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[BROADCASTER, SH...|                  []| RVU_102944|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[BROADCASTER, SH...|                  []| RVU_103514|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[BROADCASTER, SH...|                  []| RVU_103518|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[NEBO, SHORT, Er...|[[3.0.1.7, [Infor...| RVU_103873|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[NEBO, MAIN, Con...|[[3.0.1.7, [Infor...| RVU_103876|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        RVU|                  []|[[NEBO, MAIN, Con...|[[3.0.1.7, [Infor...| RVU_103878|        KN_1678993|[[NEBO, MAIN, Keu...|\n",
      "|        NOS|[[Joksimovic, Zel...|[[NEBO, MAIN, Liv...|[[3.0.1.5, [Muzie...|8act0524ESF|POMS_S_TROS_123311|[[NEBO, MAIN, NOS...|\n",
      "|        KRO|[[van der Wijst, ...|[[NEBO, MAIN, Men...|[[3.0.1.7.26, [In...|KRO_1240890|        KN_1676721|[[NEBO, MAIN, De ...|\n",
      "|        KRO|                  []|                  []|[[3.0.1.6, [Amuse...|KRO_1240932|        KN_1691711|[[NEBO, MAIN, Pub...|\n",
      "|        KRO|[[Witzier, Anita,...|[[NEBO, MAIN, Zoe...|[[3.0.1.6, [Amuse...|KRO_1242359|        KN_1682625|[[NEBO, MAIN, Mem...|\n",
      "|        KRO|                  []|[[NEBO, MAIN, Men...|[[3.0.1.7.26, [In...|KRO_1242377|        KN_1676721|[[NEBO, MAIN, De ...|\n",
      "|        KRO|[[Kamphues, Rob, ...|[[NEBO, MAIN, Kla...|[[3.0.1.6, [Amuse...|KRO_1244732|        KN_1676734|[[NEBO, MAIN, De ...|\n",
      "|        KRO|[[Witzier, Anita,...|[[BROADCASTER, MA...|[[3.0.1.6, [Amuse...|KRO_1244754|        KN_1682625|[[BROADCASTER, MA...|\n",
      "|        KRO|                  []|[[NEBO, MAIN, Men...|[[3.0.1.7.26, [In...|KRO_1244770|        KN_1676721|[[NEBO, MAIN, De ...|\n",
      "|       VPRO|                  []|[[NEBO, SHORT, Ko...|[[3.0.1.7, [Infor...|KRO_1247037| POMS_S_KRO_098924|[[NEBO, MAIN, Rep...|\n",
      "|        KRO|[[Witzier, Anita,...|[[BROADCASTER, MA...|[[3.0.1.6, [Amuse...|KRO_1254118|        KN_1676734|[[BROADCASTER, MA...|\n",
      "|        KRO|[[van der Wijst, ...|[[NEBO, MAIN, Zoe...|[[3.0.1.7.26, [In...|KRO_1254146|        KN_1676721|[[NEBO, MAIN, De ...|\n",
      "+-----------+--------------------+--------------------+--------------------+-----------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select the content features and ids\n",
    "poms = poms.select('broadcaster', 'credits', 'descriptions', 'genres', 'mid', 'seriesRef', 'titles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+----------+--------------------+\n",
      "|broadcaster|credits|        descriptions|              genres|                 mid|      seriesRef|              titles|         description|title_type|               title|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+----------+--------------------+\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[CERES, MAIN, NOS...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[CERES, MAIN, NOS...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[WHATS_ON, MAIN, ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[WHATS_ON, MAIN, ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[CERES, MAIN, NOS...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[CERES, MAIN, NOS...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[WHATS_ON, MAIN, ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[WHATS_ON, MAIN, ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[NEBO, MAIN, NOS ...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "|        NOS|     []|[[MIS, MAIN, Live...|[[3.0.1.7.21, [In...|12Jnl1022AmVerkDebat|NOSAmerikaKiest|[MIS, MAIN, NOS A...|Live uitzending v...|      MAIN|NOS Amerikaans Ve...|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gain the right title and description (as displayed on NPO Start)\n",
    "w = Window.partitionBy('mid').orderBy(sf.length(\"description.type\"))\n",
    "\n",
    "poms = (poms\n",
    "        .withColumn('titles', sf.explode('titles'))\n",
    "        .withColumn('title_type', sf.col('titles.type'))\n",
    "        .withColumn('title', sf.col('titles.value'))\n",
    "        .filter(sf.col('title_type')=='MAIN')\n",
    "        .withColumn('description', sf.explode(\"descriptions\"))\n",
    "        .filter(sf.col('description.type').isin([\"MAIN\", \"SHORT\", \"KICKER\"]))\n",
    "        .withColumn('description', sf.first('description.value').over(w))\n",
    ")\n",
    "\n",
    "poms = poms.select('broadcaster', 'credits', 'description', 'genres', 'mid', 'seriesRef', 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle extraction using the poms api\n",
    "mid = poms.select('mid').distinct()\n",
    "\n",
    "def spark_udf(data_type):\n",
    "    def create_udf(f):\n",
    "        return udf(f, data_type)\n",
    "    return create_udf\n",
    "@spark_udf(StringType())\n",
    "def spark_sub(x):\n",
    "    sub = requests.get(\"https://rs.poms.omroep.nl/v1/api/subtitles/\" + x + \"/nl_NL/CAPTION.vtt\").text.encode('ascii','ignore')\n",
    "    sub = sub.lower().split('\\n\\n') # lower and split\n",
    "    sub = sub[1:] # remove first entry of subtitles 'webvtt'\n",
    "    sub = [line.split('\\n', 2)[-1].replace('\\n', ' ') for line in sub] # remove display time info and '\\n' in subtitle text\n",
    "    sub = u\" \".join(sub)\n",
    "    return sub\n",
    "\n",
    "poms = poms.withColumn('sub', spark_sub('mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poms.write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/poms_stream/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding\n",
    "### Categorical features\n",
    "#### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "plt.style.use('bmh')\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poms = spark.read.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/poms_stream/\")\n",
    "print(poms.count())\n",
    "print(poms.printSchema())\n",
    "df = poms.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'broadcaster'\n",
    "sideinfo = (\n",
    "    poms\n",
    "    .select(sf.col('seriesRef').alias('mid'), sf.col(feature).alias('value'))\n",
    "    .withColumn('feature', sf.lit(feature))\n",
    "    .dropDuplicates()\n",
    ")\n",
    "sideinfo.show()\n",
    "sideinfo.write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/\" + feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'credits'\n",
    "\n",
    "sideinfo = (\n",
    "    poms\n",
    "    .select(sf.col('seriesRef').alias('mid'), sf.col(feature).alias('value'))\n",
    "    .withColumn('value', sf.explode('value'))\n",
    "    .withColumn('feature', sf.lit(feature))\n",
    "    .withColumn('value', sf.concat(sf.col('value.family_name'),sf.lit(', '), sf.col('value.given_name')))\n",
    "    .dropDuplicates()\n",
    ")\n",
    "sideinfo.show()\n",
    "sideinfo.write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/\" + feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'genres'\n",
    "\n",
    "sideinfo = (\n",
    "    poms\n",
    "    .select(sf.col('seriesRef').alias('mid'), sf.col(feature).alias('value'))\n",
    "    .withColumn('value', sf.explode('value'))\n",
    "    .withColumn('feature', sf.lit(feature))\n",
    "    .withColumn('value', sf.col('value.terms').cast(StringType()))\n",
    "    .dropDuplicates()\n",
    ")\n",
    "sideinfo.printSchema()\n",
    "sideinfo.show()\n",
    "sideinfo.write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/\" + feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual features\n",
    "#### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as sf\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "import re as re\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StopWordsRemover, NGram, RegexTokenizer\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.nl import Dutch\n",
    "from spacy.lang.en import English\n",
    "stopwords = spacy.lang.nl.stop_words.STOP_WORDS.union(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poms = spark.read.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/poms_stream/\")\n",
    "print(poms.count())\n",
    "poms.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform TF-IDF per feature\n",
    "| Feature     | TF-IDF amount |\n",
    "|-------------|---------------|\n",
    "| title       | 3             |\n",
    "| description | 10            |\n",
    "| subtitles   | 20            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # 10, 20\n",
    "text = 'title' #'description', 'sub'\n",
    "df = poms.select(sf.col('seriesRef').alias('mid'), sf.col(text)) \n",
    "df = df.dropna(subset=text)\n",
    "df = df.groupBy(\"mid\").agg(sf.collect_set(text)).withColumn(\"text\", sf.concat_ws(\" \", \"collect_set(\"+text+\")\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML pipeline, consisting of four stages: tokenizer, stopwordremover, countvectorizer, idf\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", minTokenLength = 4, pattern=\"\\\\W\")\n",
    "stopwordsList = [s.encode('utf-8') for s in stopwords]\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\" ,stopWords=stopwordsList)\n",
    "cv = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"rawFeatures\")\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv])\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "df = model.transform(df)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(df)\n",
    "df = idfModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top n tf-idf\n",
    "def spark_udf(data_type):\n",
    "    def create_udf(f):\n",
    "        return udf(f, data_type)\n",
    "    return create_udf\n",
    "@spark_udf(ArrayType(IntegerType()))\n",
    "def spark_argmaxes(vector):\n",
    "    if len(vector.values) > 0:\n",
    "        if len(vector.values) < n:\n",
    "            return np.argpartition(vector.values, -len(vector.values)).tolist()\n",
    "        if len(vector.values) >= n:\n",
    "            return np.argpartition(vector.values, -n)[-n:].tolist()\n",
    "    return None\n",
    "df = df.withColumn('argmaxes', spark_argmaxes('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top-n words\n",
    "word_df = df.withColumn('argmaxes', sf.explode('argmaxes')).select('mid', 'features', 'argmaxes')\n",
    "\n",
    "vocabulary = [x.encode('UTF8') for x in model.stages[2].vocabulary]\n",
    "\n",
    "@spark_udf(StringType())\n",
    "def spark_vocab(vector, x):\n",
    "    if len(vector.values) > 0:\n",
    "        return vocabulary[vector.indices[x]]\n",
    "    return None\n",
    "word_df = word_df.withColumn('value', spark_vocab('features', 'argmaxes'))\n",
    "text_tfidf = word_df.select('mid', 'value').withColumn('feature', sf.lit(text))\n",
    "text_tfidf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tfidf.write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/\" + text + \"_tfidf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}