{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "from lightfm import LightFM\n",
    "import lightfm.evaluation\n",
    "import scipy.sparse as sparse\n",
    "from scipy.special import expit\n",
    "from pyspark.sql.types import *\n",
    "from skopt import forest_minimize\n",
    "\n",
    "plt.style.use('bmh')\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 22\n",
    "\n",
    "paths = []\n",
    "for i in range(1, 23):\n",
    "    paths.append('gs://dataproc-jupyter-eileen.npo-data.nl/data/events/march/_day=' + str(i))\n",
    "interactions = spark.read.parquet(*paths)\n",
    "print(interactions.count())\n",
    "interactions.printSchema()\n",
    "\n",
    "df_int = interactions.toPandas()\n",
    "df_int = df_int.rename(columns={\"seriesRef\":\"mid\", \"npoprofileid\":\"uid\"})\n",
    "\n",
    "df_cont = spark.read.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/poms_stream/\").select('seriesRef').dropDuplicates().toPandas()\n",
    "df_cont = df_cont.rename(columns={\"seriesRef\": \"mid\"})\n",
    "\n",
    "# add together df_int['mid'] and df_cont['mid'] remove duplicates\n",
    "df_cont = pd.DataFrame(pd.concat([df_cont['mid'], df_int['mid']])).drop_duplicates()\n",
    "\n",
    "n_users = df_int.uid.unique().shape[0]\n",
    "n_items = df_cont.mid.unique().shape[0]\n",
    "sparsity = float(df_int.shape[0]) / float(n_users*n_items) * 100\n",
    "print('Threshold - Starting interactions info')\n",
    "print('Number of users: {}'.format(n_users))\n",
    "print('Number of models: {}'.format(n_items))\n",
    "print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "\n",
    "df_lim = df_int\n",
    "\n",
    "# Create mappings\n",
    "mid_to_idx = {}\n",
    "idx_to_mid = {}\n",
    "for (idx, mid) in enumerate(df_cont.mid.unique().tolist()):\n",
    "    mid_to_idx[mid] = idx\n",
    "    idx_to_mid[idx] = mid\n",
    "    \n",
    "uid_to_idx = {}\n",
    "idx_to_uid = {}\n",
    "for (idx, uid) in enumerate(df_lim.uid.unique().tolist()):\n",
    "    uid_to_idx[uid] = idx\n",
    "    idx_to_uid[idx] = uid\n",
    "    \n",
    "def map_ids(row, mapper):\n",
    "    return mapper[row]\n",
    "\n",
    "I = df_lim.uid.apply(map_ids, args=[uid_to_idx]).values\n",
    "J = df_lim.mid.apply(map_ids, args=[mid_to_idx]).values\n",
    "V = np.ones(I.shape[0])\n",
    "interactions = sparse.coo_matrix((V, (I, J)), dtype=np.float64)\n",
    "interactions = interactions.tocsr()\n",
    "\n",
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all watched stuff\n",
    "train_day = df_int[df_int['day']!=days]\n",
    "train_day = train_day[train_day['uid'].isin(df_lim.uid.tolist())]\n",
    "test_day = df_int[df_int['day']==days]\n",
    "test_day = test_day[test_day['uid'].isin(df_lim.uid.tolist())]\n",
    "\n",
    "intersect = np.intersect1d(train_day.uid.unique(), test_day.uid.unique())\n",
    "trainday = train_day\n",
    "testday = test_day[test_day['uid'].isin(intersect)].copy()\n",
    "\n",
    "# map users and items to idx\n",
    "user_list = []\n",
    "item_list = []\n",
    "for idx, row in testday.iterrows():\n",
    "    idx_user = uid_to_idx.get(row.uid)\n",
    "    idx_item = mid_to_idx.get(row.mid)\n",
    "    user_list.append(idx_user)\n",
    "    item_list.append(idx_item)\n",
    "testday['user'] = user_list\n",
    "testday['item'] = item_list\n",
    "\n",
    "def train_test_split(ratings):\n",
    "    train = ratings.copy().tocoo()\n",
    "    print(train.shape)\n",
    "    test = sparse.lil_matrix(train.shape) \n",
    "    user_index = testday.user.tolist()        \n",
    "    train = train.tolil()\n",
    "\n",
    "    for user in user_index:\n",
    "        test_ratings = testday[testday['user'] == user].item.tolist()\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "    return train.tocsr(), test.tocsr(), user_index\n",
    "\n",
    "train, test, user_index = train_test_split(interactions)\n",
    "\n",
    "eval_train = train.copy()\n",
    "non_eval_users = list(set(range(train.shape[0])) - set(user_index))\n",
    "\n",
    "eval_train = eval_train.tolil()\n",
    "for u in non_eval_users:\n",
    "    eval_train[u, :] = 0.0\n",
    "eval_train = eval_train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For recommended and watched stuff\n",
    "recwatched_df = spark.read.parquet('gs://dataproc-jupyter-eileen.npo-data.nl/data/events/recwatched').toPandas()\n",
    "recwatched_df = recwatched_df.rename(columns={\"seriesRef\":\"mid\", \"npoprofileid\":\"uid\"})\n",
    "recwatched_df\n",
    "\n",
    "train_day2 = train_day\n",
    "test_day2 = recwatched_df[recwatched_df['uid'].isin(df_lim.uid.tolist())]\n",
    "\n",
    "intersect2 = np.intersect1d(train_day2.uid.unique(), test_day2.uid.unique())\n",
    "trainday2 = train_day2\n",
    "testday2 = test_day2[test_day2['uid'].isin(intersect2)].copy()\n",
    "\n",
    "# map users and items to idx\n",
    "user_list2 = []\n",
    "item_list2 = []\n",
    "for idx, row in testday2.iterrows():\n",
    "    idx_user = uid_to_idx.get(row.uid)\n",
    "    idx_item = mid_to_idx.get(row.mid)\n",
    "    user_list2.append(idx_user)\n",
    "    item_list2.append(idx_item)\n",
    "testday2['user'] = user_list2\n",
    "testday2['item'] = item_list2\n",
    "\n",
    "def train_test_split2(ratings):\n",
    "    train2 = ratings.copy().tocoo()\n",
    "    print(train2.shape)\n",
    "    test2 = sparse.lil_matrix(train2.shape) \n",
    "    user_index2 = testday2.user.tolist()        \n",
    "    train2 = train2.tolil()\n",
    "\n",
    "    for user in user_index2:\n",
    "        test_ratings2 = testday2[testday2['user'] == user].item.tolist()\n",
    "        test2[user, test_ratings2] = ratings[user, test_ratings2]\n",
    "    return train2.tocsr(), test2.tocsr(), user_index2\n",
    "\n",
    "train2, test2, user_index2 = train_test_split2(interactions)\n",
    "\n",
    "eval_train2 = train2.copy()\n",
    "non_eval_users2 = list(set(range(train2.shape[0])) - set(user_index2))\n",
    "\n",
    "eval_train2 = eval_train2.tolil()\n",
    "for u in non_eval_users2:\n",
    "    eval_train2[u, :] = 0.0\n",
    "eval_train2 = eval_train2.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train (All watched) \" + str(len(trainday)))\n",
    "print(\"All watched \" + str(len(testday)))\n",
    "print(\"All rec and watched \" + str(len(testday2)))\n",
    "\n",
    "df_sparsity = pd.concat([trainday, testday])\n",
    "n_users = df_sparsity.uid.unique().shape[0]\n",
    "n_items = df_cont.mid.unique().shape[0]\n",
    "sparsity = float(df_int.shape[0]) / float(n_users*n_items) * 100\n",
    "print('Threshold - Starting interactions info')\n",
    "print('Number of users: {}'.format(n_users))\n",
    "print('Number of models: {}'.format(n_items))\n",
    "print('Sparsity: {:4.3f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The execution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['broadcaster', 'credits', 'description_tfidf', 'genres', 'title_tfidf', 'sub_tfidf']\n",
    "\n",
    "def combinations(features):\n",
    "    combi = []\n",
    "    for i in range(1, len(features)+1):\n",
    "        combi = combi + list(itertools.combinations(features,i))\n",
    "    return combi\n",
    "\n",
    "combi = combinations(features)\n",
    "combi.insert(0, None)\n",
    "print(len(combi))\n",
    "\n",
    "def get_itemfeatures(sideinfo):\n",
    "    feat_dlist = [{} for _ in idx_to_mid]\n",
    "    for idx, row in sideinfo.iterrows():\n",
    "        feat_key = '{}'.format(str(row.value).lower())\n",
    "        idx = mid_to_idx.get(row.mid)\n",
    "        if idx is not None:\n",
    "            feat_dlist[idx][feat_key] = 1\n",
    "    \n",
    "    item_features = DictVectorizer().fit_transform(feat_dlist)\n",
    "\n",
    "    eye = sparse.eye(item_features.shape[0], item_features.shape[0]).tocsr()\n",
    "    item_features_concat = sparse.hstack((eye, item_features))\n",
    "    item_features_concat = item_features_concat.tocsr().astype(np.float32)\n",
    "    \n",
    "    return item_features_concat\n",
    "\n",
    "def learning_curve(model, train, test, eval_train, train2, test2, eval_train2,\n",
    "                        iterarray, user_features=None,\n",
    "                        item_features=None, k=5,\n",
    "                        **fit_params):\n",
    "    old_epoch = 0\n",
    "    test_patk = []\n",
    "    test_patk_sd = []\n",
    "    test2_patk = []\n",
    "    test2_patk_sd = []\n",
    "    test_rr = []\n",
    "    test_rr_sd = []\n",
    "    test2_rr = []\n",
    "    test2_rr_sd = []\n",
    "    for epoch in iterarray:\n",
    "        print(epoch)\n",
    "        more = epoch - old_epoch\n",
    "        model.fit_partial(train, user_features=user_features,\n",
    "                          item_features=item_features,\n",
    "                          epochs=more, **fit_params)\n",
    "        this_test_pk = lightfm.evaluation.precision_at_k(model, test, item_features=item_features, train_interactions=None, k=k)\n",
    "        this_test_pk2 = lightfm.evaluation.precision_at_k(model, test2, item_features=item_features, train_interactions=None, k=k)\n",
    "        this_test_rr = lightfm.evaluation.reciprocal_rank(model, test, item_features=item_features, train_interactions=None)\n",
    "        this_test_rr2 = lightfm.evaluation.reciprocal_rank(model, test2, item_features=item_features, train_interactions=None)\n",
    "        \n",
    "        test_patk.append(np.mean(this_test_pk))\n",
    "        test_patk_sd.append(np.std(this_test_pk))\n",
    "        test2_patk.append(np.mean(this_test_pk2))\n",
    "        test2_patk_sd.append(np.std(this_test_pk2))\n",
    "        test_rr.append(np.mean(this_test_rr))\n",
    "        test_rr_sd.append(np.std(this_test_rr))\n",
    "        test2_rr.append(np.mean(this_test_rr2))\n",
    "        test2_rr_sd.append(np.std(this_test_rr2))\n",
    "        row = [epoch, test_patk[-1], test_patk_sd[-1], test2_patk[-1], test2_patk_sd[-1], test_rr[-1], test_rr_sd[-1], test2_rr[-1], test2_rr_sd[-1]]\n",
    "        results.append(row)\n",
    "    return model, test_patk, test_patk_sd, test2_patk, test2_patk_sd, test_rr, test_rr_sd, test2_rr, test2_rr_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for j in range (0, len(combi)):\n",
    "    print(time.asctime()) \n",
    "    feature = combi[j]\n",
    "    print(feature, j)\n",
    "\n",
    "    if feature == None: \n",
    "        item_features_concat = None\n",
    "    else: \n",
    "        paths = []\n",
    "        for i in range(0, len(feature)):\n",
    "            paths.append('gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/' + feature[i])\n",
    "        sideinfo = spark.read.parquet(*paths)\n",
    "\n",
    "        sideinfo = sideinfo.toPandas()\n",
    "        sideinfo['value'] = sideinfo.value.str.encode('utf-8')\n",
    "        sideinfo = sideinfo[sideinfo['mid'].isin(df_lim.mid.tolist())]\n",
    "        sideinfo = sideinfo[sideinfo.groupby('value').value.transform(len) > 1] #remove unique content featuers\n",
    "        item_features_concat = get_itemfeatures(sideinfo)\n",
    "    \n",
    "    result = []\n",
    "    model = LightFM(loss='warp', random_state=2016)\n",
    "    model.fit(train, item_features=item_features_concat, epochs=0)\n",
    "\n",
    "    iterarray = range(10, 110, 10)\n",
    "    model, test_patk, test_patk_sd, test2_patk, test2_patk_sd, test_rr, test_rr_sd, test2_rr, test2_rr_sd = learning_curve(\n",
    "        model, train, test, eval_train, train2, test2, eval_train2, iterarray, item_features=item_features_concat,k=5, **{'num_threads': 4}) #num_threads 1\n",
    "\n",
    "    \n",
    "    results.append(result)\n",
    "    print(time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.columns = ['epoch', 'test_p5', 'p5_std', 'test_p52', 'p5_std2', 'test_r-rank', 'rank_std', 'test_r-rank2', 'rank_std2']\n",
    "indeces = []\n",
    "features = []\n",
    "df = df.dropna()\n",
    "for i in range(0, len(combi)):\n",
    "    for j in range(0, 10):\n",
    "        indeces.append(i)\n",
    "        features.append(str(combi[i]))\n",
    "df['combi'] = indeces\n",
    "df['features'] = features\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(df).write.parquet(\"gs://dataproc-jupyter-eileen.npo-data.nl/data/results/marchv3results58-64(2)-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = combi[48] # ('broadcaster', 'description_tfidf', 'genres', 'title_tfidf')\n",
    "\n",
    "paths = []\n",
    "for i in range(0, len(feature)):\n",
    "    paths.append('gs://dataproc-jupyter-eileen.npo-data.nl/data/content_features/' + feature[i])\n",
    "sideinfo = spark.read.parquet(*paths)\n",
    "\n",
    "sideinfo = sideinfo.toPandas()\n",
    "sideinfo['value'] = sideinfo.value.str.encode('utf-8')\n",
    "sideinfo = sideinfo[sideinfo['mid'].isin(df_lim.mid.tolist())]\n",
    "item_features_concat = get_itemfeatures(sideinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_wsideinfo(params):\n",
    "    epochs, learning_rate,\\\n",
    "    no_components, item_alpha,\\\n",
    "    scale = params\n",
    "    \n",
    "    user_alpha = item_alpha * scale\n",
    "    model = LightFM(loss='warp',\n",
    "                    random_state=2016,\n",
    "                    learning_rate=learning_rate,\n",
    "                    no_components=no_components,\n",
    "                    user_alpha=user_alpha,\n",
    "                    item_alpha=item_alpha)\n",
    "    model.fit(train, epochs=epochs,\n",
    "              item_features=item_features_concat,\n",
    "              num_threads=4, verbose=True)\n",
    "    \n",
    "    patks = lightfm.evaluation.precision_at_k(model, test,\n",
    "                                              item_features=item_features_concat,\n",
    "                                              train_interactions=None,\n",
    "                                              k=5, num_threads=3)\n",
    "\n",
    "    mapatk = np.mean(patks)\n",
    "    # Make negative because we want to _minimize_ objective\n",
    "    out = -mapatk\n",
    "    # Weird shit going on\n",
    "    if np.abs(out + 1) < 0.01 or out < -1.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "space = [(1, 120), # epochs\n",
    "         (10**-3, 1.0, 'log-uniform'), # learning_rate\n",
    "         (20, 200), # no_components\n",
    "         (10**-5, 10**-3, 'log-uniform'), # item_alpha\n",
    "         (0.001, 1., 'log-uniform') # user_scaling\n",
    "        ]\n",
    "item_features = item_features_concat.astype(np.float32)\n",
    "res_fm_itemfeat_precision = forest_minimize(objective_wsideinfo, space, n_calls=50,\n",
    "                                  random_state=0,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximimum p@k found: {:6.5f}'.format(-res_fm_itemfeat_precision.fun))\n",
    "print('Optimal parameters:')\n",
    "params = ['epochs', 'learning_rate', 'no_components', 'item_alpha', 'scaling']\n",
    "for (p, x_) in zip(params, res_fm_itemfeat_precision.x):\n",
    "    print('{}: {}'.format(p, x_))\n",
    "print('Standard deviation: ' + str(np.std(-res_fm_itemfeat_precision.func_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized hyperparameters\n",
    "epochs = 89\n",
    "learning_rate = 0.0146853682318\n",
    "no_components = 168\n",
    "item_alpha = 0.00086386659459\n",
    "scale = 0.325637504106\n",
    "\n",
    "user_alpha = item_alpha * scale\n",
    "model = LightFM(loss='warp',\n",
    "                random_state=2016,\n",
    "                learning_rate=learning_rate,\n",
    "                no_components=no_components,\n",
    "                user_alpha=user_alpha,\n",
    "                item_alpha=item_alpha)\n",
    "model.fit(interactions, epochs=epochs,\n",
    "          item_features=item_features_concat,\n",
    "          num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = lightfm.evaluation.precision_at_k(model, test, item_features=item_features_concat, train_interactions=None, k=5)\n",
    "precision_test2 = lightfm.evaluation.precision_at_k(model, test2, item_features=item_features_concat, train_interactions=None, k=5)\n",
    "rank_test = lightfm.evaluation.reciprocal_rank(model, test, item_features=item_features_concat, train_interactions=None)\n",
    "rank_test2 = lightfm.evaluation.reciprocal_rank(model, test2, item_features=item_features_concat, train_interactions=None)\n",
    "\n",
    "print(\"Precision mean: \" + str(np.mean(precision_test)))\n",
    "print(\"Precision std: \" + str(np.std(precision_test)))\n",
    "print(\"Precision2 mean: \" + str(np.mean(precision_test2)))\n",
    "print(\"Precision2 std: \" + str(np.std(precision_test2)))\n",
    "print(\"Rank mean: \" + str(np.mean(rank_test)))\n",
    "print(\"Rank std: \" + str(np.std(rank_test)))\n",
    "print(\"Rank2 mean: \" + str(np.mean(rank_test2)))\n",
    "print(\"Rank2 std: \" + str(np.std(rank_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(columns=['itemlist','scores', 'userlist'])\n",
    "for i in range(0, len(user_list2)):\n",
    "    scores = model.predict(np.int32(user_list2[i], dtype=np.int32), item_list) #31\n",
    "    score_df = pd.DataFrame({'itemlist' : item_list, 'scores' : scores}).drop_duplicates()\n",
    "    score_df = score_df.sort_values('scores', ascending=False)\n",
    "    score_df['userlist'] = user_list2[i]\n",
    "    predictions_df = pd.concat([predictions_df, score_df.head(5)])\n",
    "series_ref = []\n",
    "for x in predictions_df['itemlist'].tolist():\n",
    "    series_ref.append(idx_to_mid.get(x))\n",
    "predictions_df['seriesRef'] = series_ref\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show recommendations for a random user\n",
    "rando = user_list2[random.randint(0, len(user_list2))]\n",
    "print(rando)\n",
    "user = rando\n",
    "user_id = idx_to_uid.get(user)\n",
    "print(user_id)\n",
    "scores = model.predict(np.int32(user, dtype=np.int32), item_list) #31\n",
    "score_df = pd.DataFrame({'itemlist' : item_list, 'scores' : scores})\n",
    "score_df = score_df.drop_duplicates()\n",
    "score_df = score_df.sort_values('scores', ascending=False)\n",
    "series_ref = []\n",
    "for x in score_df['itemlist'].tolist():\n",
    "    series_ref.append(idx_to_mid.get(x))\n",
    "score_df['seriesRef'] = series_ref\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}